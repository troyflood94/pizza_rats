{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import scipy as stats\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "from scipy.stats import chi2_contingency\n",
    "import folium\n",
    "#from selenium import webdriver\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantpath= Path(\"csv_folder/restaurant_data.csv\")\n",
    "restaurantfile=pd.read_csv(restaurantpath,encoding=\"UTF-8\")\n",
    "restaurantfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantfile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define subset of columns to consider for duplicates\n",
    "restaurantfile['CAMIS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unnessecary columns\n",
    "restaurants_to_keep=['CAMIS','BORO','DBA', 'ZIPCODE','ACTION','CUISINE DESCRIPTION','INSPECTION DATE','GRADE', 'VIOLATION CODE']\n",
    "restaurantfile=restaurantfile[restaurants_to_keep].copy()\n",
    "#restaruantfile = restaruantfile.drop(columns=['BUILDING','STREET', 'PHONE', 'Community Board', 'Council District', 'Census Tract', 'BIN', 'BBL', 'NTA', 'RECORD DATE', 'GRADE DATE'])\n",
    "restaurantfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop restaurants that don't have a grade (i.e., NaN) from the dataframe\n",
    "#query_df['grade'].unique()\n",
    "clean_grade_df = restaurantfile.dropna(subset=['GRADE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting unique value lists which should be helpful later when making calls. this syntax can work for any column.\n",
    "clean_grade_df['CUISINE DESCRIPTION'].unique().tolist()\n",
    "clean_grade_df['BORO'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code worked but i think we will have to run the dates through that filter code to get it sorted. I am holdingoff until class to do this.\n",
    "clean_grade_df.sort_values('INSPECTION DATE',ascending=False)\n",
    "clean_grade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format dates, adds a date column, fills NaN, get rid of decimal in zip code\n",
    "clean_grade_df['INSPECTION DATE'] = pd.to_datetime(clean_grade_df['INSPECTION DATE']).dt.date\n",
    "clean_grade_df['Date']=clean_grade_df['INSPECTION DATE']\n",
    "clean_grade_df['ZIPCODE'].fillna(-1,inplace=True)\n",
    "clean_grade_df['ZIPCODE'] = clean_grade_df['ZIPCODE'].astype(int)\n",
    "clean_grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need denominator to be unique restaurants\n",
    "clean_grade_unique=clean_grade_df.drop_duplicates(subset=['CAMIS'])\n",
    "clean_grade_unique.reset_index(drop=True, inplace=True)\n",
    "clean_grade_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 1: How many unique A, B, C restaurants were there in New York City from September 2010-September 2017?\n",
    "gradecountscitywide=clean_grade_unique['GRADE'].value_counts()\n",
    "gradecountscitywide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grades by count pie chart:\n",
    "explode = (0.1, 0.1, 0.2, 0.3,0.5)\n",
    "\n",
    "#Pie chart\n",
    "plt.pie(gradecountscitywide,explode=explode, labels='ABCPN',\n",
    "        autopct=\"%1.1f%%\", shadow=True, startangle=180)\n",
    "plt.title('Grades Counts')\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 1a: Is there an association between resaurant cuisine and rating?\n",
    "# Extract unique cuisine descriptions\n",
    "cuisinedescriptions = clean_grade_unique['CUISINE DESCRIPTION'].unique()\n",
    "cuisinedescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pare down list of cuisines for Chi-Square test\n",
    "\n",
    "# Define a mapping dictionary for collapsing cuisines\n",
    "cuisine_mapping = {\n",
    "    'American': 'American',\n",
    "    'Other': 'Other',\n",
    "    'Korean': 'Asian',\n",
    "    'Mexican': 'Latin American',\n",
    "    'Latin American': 'Latin American',\n",
    "    'Frozen Desserts': 'Desserts/Baked Goods',\n",
    "    'Hotdogs': 'Fast Food',\n",
    "    'Pizza': 'Pizza',\n",
    "    'French':'European',\n",
    "    'Bottled Beverages':'Coffee/Tea/Beverages',\n",
    "    'Italian':'Italian',\n",
    "    'Tex-Mex':'Latin American',\n",
    "    'Japanese':'Asian',\n",
    "    'Spanish':'European',\n",
    "    'Coffee/Tea':'Coffee/Tea/Beverages',\n",
    "    'Mediterranean':'European',\n",
    "    'Caribbean':'Caribbean',\n",
    "    'Middle Eastern': 'Middle Eastern',\n",
    "    'German':'European',\n",
    "    'Hamburgers':'Fast Food',\n",
    "    'Sandwiches/Salads/Mixed Buffet':'Deli',\n",
    "    'Vegan':'Special Diet',\n",
    "    'Bagels/Pretzels':'Deli',\n",
    "    'Jewish/Kosher':'Special Diet',\n",
    "    'Filipino':'Asian',\n",
    "    'Indian':'Indian',\n",
    "    'Sandwiches':'Deli',\n",
    "    'Seafood':'Seafood',\n",
    "    'Chinese':'Asian',\n",
    "    'Eastern European':'European',\n",
    "    'Donuts':'Desserts/Baked Goods',\n",
    "    'Soups/Salads/Sandwiches':'Deli',\n",
    "    'Juice, Smoothies, Fruit Salads':'Juices/Smoothies',\n",
    "    'African':'African',\n",
    "    'Russian':'European',\n",
    "    'Ethiopian':'African',\n",
    "    'Mexican':'Latin American',\n",
    "    'Steakhouse':'Steakhouse',\n",
    "    'Irish':'European'\n",
    "}\n",
    "\n",
    "# Replace values in the 'CUISINES' column using the mapping dictionary\n",
    "clean_grade_unique['CollapsedCUISINES'] = clean_grade_unique['CUISINE DESCRIPTION'].replace(cuisine_mapping)\n",
    "\n",
    "cuisinedescriptionsnew = clean_grade_unique['CollapsedCUISINES'].unique()\n",
    "cuisinedescriptionsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there an association between restaurant type and rating? -Chi-Square\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(pd.crosstab(clean_grade_unique['CollapsedCUISINES'], clean_grade_unique['GRADE']))\n",
    "\n",
    "print(\"Chi-square test statistic:\", chi2)\n",
    "print(f\"p-value: {p:.5f}\")\n",
    "print(\"Degress of Freedom:\", dof)\n",
    "\n",
    "cuisinebyratingdf=pd.crosstab(clean_grade_unique['CollapsedCUISINES'], clean_grade_unique['GRADE'])\n",
    "cuisinebyratingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 3: Number of grades by Borough among unique restaurants\n",
    "gradecounts= clean_grade_unique.groupby(['BORO', 'GRADE']).size().reset_index(name='count')\n",
    "\n",
    "Boroughs = gradecounts['BORO']\n",
    "counts = gradecounts['count']\n",
    "grades = gradecounts['GRADE']\n",
    "\n",
    "transposecounts = gradecounts.pivot(index='BORO', columns='GRADE', values='count').fillna(0)\n",
    "\n",
    "transposecounts.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Restaurant Grades')\n",
    "plt.title('Number of Restaurant Grades by Borough, 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there an association between Borough and rating? -Chi-Square\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(pd.crosstab(clean_grade_unique['GRADE'], clean_grade_unique['BORO']))\n",
    "\n",
    "print(\"Chi-square test statistic:\", chi2)\n",
    "print(f\"p-value: {p:.5f}\")\n",
    "print(\"Degress of Freedom:\", dof)\n",
    "\n",
    "gradebyboro=pd.crosstab(clean_grade_unique['GRADE'], clean_grade_unique['BORO'])\n",
    "gradebyboro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crestaurants=clean_grade_unique.loc[clean_grade_unique['GRADE']=='C']\n",
    "crestaurants\n",
    "#italian_df=clean_grade_unique.loc[clean_grade_unique['CUISINE DESCRIPTION']=='Italian']\n",
    "#italian_df.loc[italian_df['GRADE']=='C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=restaurantfile['ACTION'].unique()\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closedrestaurants=restaurantfile.loc[restaurantfile['ACTION']=='Establishment Closed by DOHMH. Violations were cited in the following area(s) and those requiring immediate action were addressed.']\n",
    "closedrestaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3A. Do certain boroughs have more restaurant violations? Violations per restaurant by borough\n",
    "violationcount= clean_grade_df.groupby(['BORO']).size().reset_index(name='count')\n",
    "\n",
    "camis_df1 = pd.DataFrame({\n",
    "    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'],\n",
    "    'Count': [104, 35, 159, 62, 12]\n",
    "})\n",
    "\n",
    "violation_df2 = pd.DataFrame({\n",
    "    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'],\n",
    "    'Count': [252, 91, 371, 119, 29]\n",
    "})\n",
    "\n",
    "#Merge the DataFrames on 'borough'\n",
    "merged_df = pd.merge(camis_df1, violation_df2, on='borough', suffixes=('_restaurants', '_violations'))\n",
    "\n",
    "#Perform the division\n",
    "merged_df['Violations_per_Restaurant'] = merged_df['Count_violations'] / merged_df['Count_restaurants']\n",
    "\n",
    "#Drop columns\n",
    "merged_df.drop(['Count_restaurants', 'Count_violations'], axis=1, inplace=True)\n",
    "\n",
    "#Display the result\n",
    "print(\"\\nMerged DataFrame with Division:\")\n",
    "print(merged_df)\n",
    "\n",
    "merged_df.plot(kind='bar', x='borough', y='Violations_per_Restaurant')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Violations per Restaurant')\n",
    "plt.title('Violations per Restaurant by Borough, New York City 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_grade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a. Do certain Boroughs have more restaurant violations? -Chi square test\n",
    "#Calculate number of violations per restaurant\n",
    "violationsperrestaurant = clean_grade_df.groupby('CAMIS')['VIOLATION CODE'].nunique().reset_index()\n",
    "#rename columns and create dataframe, now for each restaurant, we have a variable with their number of violations\n",
    "violationsperrestaurant.columns = ['CAMIS', 'violationsperrestaurant']\n",
    "violationsperrestaurant_df = pd.DataFrame(violationsperrestaurant)\n",
    "violationsperrestaurant_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with the original dataset showing unique restaurant with their number of violations\n",
    "clean_grade_unique2 = clean_grade_unique.merge(violationsperrestaurant_df, on='CAMIS', how='left')\n",
    "clean_grade_unique2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_violations = clean_grade_unique2['violationsperrestaurant'].max()\n",
    "max_violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_violations = clean_grade_unique2['violationsperrestaurant'].min()\n",
    "min_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins\n",
    "violbins = [0, 1, 3, 5, 7]\n",
    "#Create the names for the four bins\n",
    "group_names = [\"Zero Violations\", \"One Violation\", \"3-5 Violations\", \"5-7 Violations\"]\n",
    "\n",
    "#Create a new column 'violations_category' based on 'num_violations' column\n",
    "clean_grade_unique2['violations_category'] = pd.cut(clean_grade_unique2['violationsperrestaurant'], bins=violbins, labels=group_names)\n",
    "\n",
    "#Group by 'borough' and 'violations_category', then count the number of restaurants in each group\n",
    "violations_count = clean_grade_unique2.groupby(['BORO', 'violations_category']).size().reset_index(name='restaurant_count')\n",
    "\n",
    "print(violations_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'borough' and 'violations_category', then count the number of restaurants in each group\n",
    "violations_count = clean_grade_unique2.groupby(['BORO', 'violations_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting the clustered bar chart\n",
    "violations_count.plot(kind='bar', figsize=(12, 8))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Number of Restaurants by Borough and Violations Category')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Restaurants')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Violations Category')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(violations_count)\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN RAT DATA DO NOT PUT PIZZA DATA BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratpath= Path(\"csv_folder/rat_sightings.csv\")\n",
    "ratfile=pd.read_csv(ratpath,encoding=\"UTF-8\")\n",
    "ratfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratfile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#came up with way to easily filter the main DF by columns. This can easily be amended by adding column titles to columns_to_keep and rerunning the block.\n",
    "#i took facility type out Facililty Type because it is only Nans. scroll down to see output confirming.\n",
    "columns_to_keep=['Borough','Incident Zip','Created Date','Location Type','City','Status','Complaint Type']\n",
    "clean_rats_df=ratfile[columns_to_keep].copy()\n",
    "clean_rats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed the zip code formatting, had to fill NaNs but we can discuss dropping them maybe? Im having trouble picturing how it will effect the final project.\n",
    "#next we need to run that code on the date here, i cant seem to locate it\n",
    "clean_rats_df['Incident Zip'].fillna(0,inplace=True)\n",
    "clean_rats_df['Incident Zip'] = clean_rats_df['Incident Zip'].astype(int)\n",
    "clean_rats_df['Created Date'] = pd.to_datetime(clean_rats_df['Created Date']).dt.date\n",
    "clean_rats_df['Date']=clean_rats_df['Created Date']\n",
    "clean_rats_df['ZIPCODE']=clean_rats_df['Incident Zip']\n",
    "clean_rats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 4: Do certain Boroughs have more rat sightings?\n",
    "ratcounting=  clean_rats_df.groupby(['Borough']).size().reset_index(name='count')\n",
    "\n",
    "ratcounting.plot(kind='bar', x='Borough', y='count')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Rat Sightings')\n",
    "plt.title('Number of Rat Sightings by Borough, 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider per capita data. Find population and divide the rat sightings by the number of people.\n",
    "ratcounting = clean_rats_df.groupby(['Borough']).size().reset_index(name='count')\n",
    "\n",
    "# Your population data\n",
    "borough_pops = pd.DataFrame({'Borough': ['BRONX', 'BROOKLYN', 'MANHATTAN', 'QUEENS', 'STATEN ISLAND'],\n",
    "                             'Population': [1471160, 2736074, 1694251, 2405464, 495747]})\n",
    "\n",
    "# Merge rat sightings data with population data\n",
    "ratcounting = ratcounting.merge(borough_pops, on='Borough')\n",
    "\n",
    "# Calculate rat sightings per capita\n",
    "ratcounting['rat_per_capita'] = ratcounting['count'] / ratcounting['Population']\n",
    "\n",
    "# Plotting\n",
    "ratcounting.plot(kind='bar', x='Borough', y='rat_per_capita')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Rat Sightings per Capita')\n",
    "plt.title('Number of Rat Sightings per Capita by Borough, 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 4a: Do certain zip codes have more rat sightings?\n",
    "clean_rats_df['ZIPCODE']=clean_rats_df['ZIPCODE'].astype(str)\n",
    "rat_burroughs = clean_rats_df[clean_rats_df['ZIPCODE'].str.len() == 5]\n",
    "#rat_burroughs=clean_rats_df[clean_rats_df['Complaint Type']=='Rodent'].groupby('ZIPCODE').size()\n",
    "rat_burroughs.groupby('ZIPCODE').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create high, med, low rat sightings\n",
    "rat_concentration = rat_burroughs.groupby('ZIPCODE').size().reset_index(name='ratconcentration')\n",
    "print(rat_concentration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_concentration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_bins = [1, 162,754, 3124]\n",
    "\n",
    "# # Create the names for the five bins\n",
    "group_names = [\"Low Rat Concentration\", \"Average Rat Concentration\", \"High Rat Concentration\"]\n",
    "# count number of rat sightings per zipcode\n",
    "# categorize each zip codes as high medium and low\n",
    "rat_concentration = rat_burroughs.groupby('ZIPCODE').size().reset_index(name='ratconcentration')\n",
    "\n",
    "# Reset index and rename columns (if necessary)\n",
    "rat_concentration_df = rat_concentration.rename(columns={'ZIPCODE': 'zipcode'})\n",
    "\n",
    "rat_concentration_df['ratbins'] = pd.cut(rat_concentration_df['ratconcentration'], bins=rat_bins, labels=group_names, include_lowest=True)\n",
    "rat_concentration_df = rat_concentration_df.rename(columns={'ZIPCODE': 'zipcode'})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(rat_concentration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_concentration_df = pd.DataFrame(rat_concentration_df)\n",
    "rat_concentration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in lat long data to zip codes for mapping\n",
    "latlongpath= Path(\"csv_folder/zip_lat_long.csv\")\n",
    "latlong=pd.read_csv(latlongpath,encoding=\"UTF-8\")\n",
    "\n",
    "latlong.rename(columns={'ZIP': 'zipcode'}, inplace=True)\n",
    "\n",
    "latlong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latlong['zipcode'].dtype)\n",
    "print(rat_concentration_df['zipcode'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_concentration_df['zipcode'] = rat_concentration_df['zipcode'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(latlong, rat_concentration_df, on='zipcode')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    'Low Rat Concentration': 'green',\n",
    "    'Average Rat Concentration': 'orange',\n",
    "    'High Rat Concentration': 'red'\n",
    "}\n",
    "\n",
    "#Make the map centered around New York City\n",
    "mymap = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "#For loop to add markers to the map\n",
    "for index, row in merged_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LAT'], row['LNG']],\n",
    "        radius=3,\n",
    "        color=color_map[row['ratbins']],\n",
    "        fill=True,\n",
    "        fill_color=color_map[row['ratbins']],\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"ZIP: {row['zipcode']}<br>Concentration: {row['ratconcentration']}<br>Category: {row['ratbins']}\"\n",
    "    ).add_to(mymap)\n",
    "\n",
    "#Display the map\n",
    "mymap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_grade_unique2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_grade_unique2.rename(columns={'ZIPCODE': 'zipcode'}, inplace=True)\n",
    "clean_grade_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmerge=pd.merge(rat_concentration_df,clean_grade_unique2, on='zipcode')\n",
    "finalmerge.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forregression_df= ['zipcode', 'ratconcentration', 'violationsperrestaurant']\n",
    "regressiondf = finalmerge[forregression_df]\n",
    "\n",
    "regressiondf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "X = regressiondf['ratconcentration']\n",
    "y = regressiondf['violationsperrestaurant']\n",
    "\n",
    "# Perform linear regression using scipy\n",
    "slope, intercept, r_value, p_value, std_err = linregress(X.values, y)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Slope: {slope}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"R-squared: {r_value**2}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "print(f\"Standard error: {std_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data points\n",
    "plt.scatter(X, y, label='Data points')\n",
    "\n",
    "# Plotting the regression line\n",
    "plt.plot(X, intercept + slope * X, color='red', label='Regression line')\n",
    "\n",
    "plt.xlabel('Rat Concentration')\n",
    "plt.ylabel('Violations per Restaurant')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

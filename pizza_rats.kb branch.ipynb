{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import scipy as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaruantpath= Path(\"csv_folder/restaurant_data.csv\")\n",
    "restaruantfile=pd.read_csv(restaruantpath,encoding=\"UTF-8\")\n",
    "restaruantfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalize Inspection Date columns\n",
    "# query_df['inspection_date']=pd.to_datetime(query_df['inspection_date']).dt.normalize()\n",
    "# print(query_df['inspection_date'].head())\n",
    "# print(query_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unnessecary columns\n",
    "restaurants_to_keep=['CAMIS','VIOLATION DESCRIPTION','DBA','BORO', 'ZIPCODE','CUISINE DESCRIPTION','INSPECTION DATE','GRADE']\n",
    "restaruantfile=restaruantfile[restaurants_to_keep].copy()\n",
    "#restaruantfile = restaruantfile.drop(columns=['BUILDING','STREET', 'PHONE', 'Community Board', 'Council District', 'Census Tract', 'BIN', 'BBL', 'NTA', 'RECORD DATE', 'GRADE DATE'])\n",
    "restaruantfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop restaurants that don't have a grade (i.e., NaN) from the dataframe\n",
    "#query_df['grade'].unique()\n",
    "clean_grade_df = restaruantfile.dropna(subset=['GRADE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting unique value lists which should be helpful later when making calls. this syntax can work for any column.\n",
    "clean_grade_df['CUISINE DESCRIPTION'].unique().tolist()\n",
    "clean_grade_df['BORO'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code worked but i think we will have to run the dates through that filter code to get it sorted. I am holdingoff until class to do this.\n",
    "clean_grade_df.sort_values('INSPECTION DATE',ascending=False)\n",
    "clean_grade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict dataset to just September 2010 to September 2017\n",
    "clean_grade_df['INSPECTION DATE'] = pd.to_datetime(clean_grade_df['INSPECTION DATE']).dt.date\n",
    "clean_grade_df['Date']=clean_grade_df['INSPECTION DATE']\n",
    "clean_grade_df['ZIPCODE'].fillna(-1,inplace=True)\n",
    "clean_grade_df['ZIPCODE'] = clean_grade_df['ZIPCODE'].astype(int)\n",
    "clean_grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need denominator to be unique restaurants\n",
    "\n",
    "clean_grade_unique=clean_grade_df.drop_duplicates(subset=['CAMIS'])\n",
    "clean_grade_unique.reset_index(drop=True, inplace=True)\n",
    "clean_grade_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 1: How many unique A, B, C restaurants were there in New York City from September 2010-September 2017?\n",
    "gradecountscitywide=clean_grade_unique['GRADE'].value_counts()\n",
    "gradecountscitywide\n",
    "\n",
    "#Pie chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique cuisine descriptions\n",
    "cuisinedescriptions = clean_grade_unique['CUISINE DESCRIPTION'].unique()\n",
    "cuisinedescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pare down list of cuisines for Chi-Square test\n",
    "\n",
    "# Define a mapping dictionary for collapsing cuisines\n",
    "cuisine_mapping = {\n",
    "    'American': 'American',\n",
    "    'Other': 'Other',\n",
    "    'Korean': 'Asian',\n",
    "    'Mexican': 'Latin American',\n",
    "    'Latin American': 'Latin American',\n",
    "    'Frozen Desserts': 'Desserts/Baked Goods',\n",
    "    'Hotdogs': 'Fast Food',\n",
    "    'Pizza': 'Pizza',\n",
    "    'French':'European',\n",
    "    'Bottled Beverages':'Coffee/Tea/Beverages',\n",
    "    'Italian':'Italian',\n",
    "    'Tex-Mex':'Latin American',\n",
    "    'Japanese':'Asian',\n",
    "    'Spanish':'European',\n",
    "    'Coffee/Tea':'Coffee/Tea/Beverages',\n",
    "    'Mediterranean':'European',\n",
    "    'Caribbean':'Caribbean',\n",
    "    'Middle Eastern': 'Middle Eastern',\n",
    "    'German':'European',\n",
    "    'Hamburgers':'Fast Food',\n",
    "    'Sandwiches/Salads/Mixed Buffet':'Deli',\n",
    "    'Vegan':'Special Diet',\n",
    "    'Bagels/Pretzels':'Deli',\n",
    "    'Jewish/Kosher':'Special Diet',\n",
    "    'Filipino':'Asian',\n",
    "    'Indian':'Indian',\n",
    "    'Sandwiches':'Deli',\n",
    "    'Seafood':'Seafood',\n",
    "    'Chinese':'Asian',\n",
    "    'Eastern European':'European',\n",
    "    'Donuts':'Desserts/Baked Goods',\n",
    "    'Soups/Salads/Sandwiches':'Deli',\n",
    "    'Juice, Smoothies, Fruit Salads':'Juices/Smoothies',\n",
    "    'African':'African',\n",
    "    'Russian':'European',\n",
    "    'Ethiopian':'African',\n",
    "    'Mexican':'Latin American',\n",
    "    'Steakhouse':'Steakhouse',\n",
    "    'Irish':'European'\n",
    "}\n",
    "\n",
    "# Replace values in the 'CUISINES' column using the mapping dictionary\n",
    "clean_grade_unique['CollapsedCUISINES'] = clean_grade_unique['CUISINE DESCRIPTION'].replace(cuisine_mapping)\n",
    "\n",
    "cuisinedescriptionsnew = clean_grade_unique['CollapsedCUISINES'].unique()\n",
    "cuisinedescriptionsnew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b Is there an association between restaurant type and rating among unique restaurants? -Chi-Square\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(pd.crosstab(clean_grade_unique['CollapsedCUISINES'], clean_grade_unique['GRADE']))\n",
    "\n",
    "print(\"Chi-square test statistic:\", chi2)\n",
    "print(f\"p-value: {p:.5f}\")\n",
    "print(\"Degress of Freedom:\", dof)\n",
    "\n",
    "cuisinebyratingdf=pd.crosstab(clean_grade_unique['CollapsedCUISINES'], clean_grade_unique['GRADE'])\n",
    "cuisinebyratingdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe these 7 restaurants with C ratings: Where are they located? What are their names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 3: Number of grades by Borough\n",
    "#restaurantcount = clean_grade_df.groupby(['BORO', 'DBA']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 3: Number of grades by Borough\n",
    "gradecounts= clean_grade_df.groupby(['BORO', 'GRADE']).size().reset_index(name='count')\n",
    "\n",
    "boroughs = gradecounts['BORO']\n",
    "counts = gradecounts['count']\n",
    "grades = gradecounts['GRADE']\n",
    "\n",
    "transposecounts = gradecounts.pivot(index='BORO', columns='GRADE', values='count').fillna(0)\n",
    "\n",
    "transposecounts.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Restaurant Grades')\n",
    "plt.title('Number of Restaurant Grades by Borough, 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Pie Chart for each Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquerestboro=clean_grade_unique.groupby('BORO').count()\n",
    "uniquerestboro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationcount= clean_grade_df.groupby(['BORO']).size().reset_index(name='count')\n",
    "violationcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3a: Do certain boroughs have more restaurant violations?\n",
    "violationcount= clean_grade_df.groupby(['BORO']).size().reset_index(name='count')\n",
    "\n",
    "camis_df1 = pd.DataFrame({\n",
    "    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'],\n",
    "    'Count': [104, 35, 159, 62, 12]\n",
    "})\n",
    "\n",
    "violation_df2 = pd.DataFrame({\n",
    "    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'],\n",
    "    'Count': [252, 91, 371, 119, 29]\n",
    "})\n",
    "\n",
    "# Display the original DataFrames\n",
    "print(\"DataFrame 1:\")\n",
    "print(camis_df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(violation_df2)\n",
    "\n",
    "# Merge the DataFrames on 'borough'\n",
    "merged_df = pd.merge(camis_df1, violation_df2, on='borough', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Perform the division\n",
    "merged_df['Count_Division'] = merged_df['Count_df2'] / merged_df['Count_df1']*100\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nMerged DataFrame with Division:\")\n",
    "print(merged_df)\n",
    "\n",
    "#hello\n",
    "\n",
    "\n",
    "#ratboroughs = ratcounting['Borough']\n",
    "#ratcounts = ratcounting.groupby('Borough').count()['Complaint Type']\n",
    "\n",
    "\n",
    "#rattransposecounts = ratcounting.pivot(index='Borough', columns=ratboroughs, values=ratcounts).fillna(0)\n",
    "\n",
    "merged_df.plot(kind='bar', x='borough', y='Count_Division')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Borough Restaurant Violations by Percentage')\n",
    "plt.title(' Violation Percentage by Borough')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do certain Zip Codes have higher restaurant ratings?\n",
    "#zipcountscitywide=clean_grade_unique['ZIPCODE'].value_counts()\n",
    "#zipcountscitywide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_grade_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN RAT DATA DO NOT PUT PIZZA DATA BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratpath= Path(\"csv_folder/rat_sightings.csv\")\n",
    "ratfile=pd.read_csv(ratpath,encoding=\"UTF-8\")\n",
    "ratfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#came up with way to easily filter the main DF by columns. This can easily be amended by adding column titles to columns_to_keep and rerunning the block.\n",
    "#i took facility type out Facililty Type because it is only Nans. scroll down to see output confirming.\n",
    "columns_to_keep=['Borough','Incident Zip','Created Date','Location Type','City','Status','Complaint Type']\n",
    "clean_rats_df=ratfile[columns_to_keep].copy()\n",
    "clean_rats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed the zip code formatting, had to fill NaNs but we can discuss dropping them maybe? Im having trouble picturing how it will effect the final project.\n",
    "#next we need to run that code on the date here, i cant seem to locate it\n",
    "clean_rats_df['Incident Zip'].fillna(-1,inplace=True)\n",
    "clean_rats_df['Incident Zip'] = clean_rats_df['Incident Zip'].astype(int)\n",
    "clean_rats_df['Created Date'] = pd.to_datetime(clean_rats_df['Created Date']).dt.date\n",
    "clean_rats_df['Date']=clean_rats_df['Created Date']\n",
    "clean_rats_df['ZIPCODE']=clean_rats_df['Incident Zip']\n",
    "clean_rats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 2: How many rat sightings were there in New York City from September 2010-September 2017?\n",
    "clean_rats_df['Complaint Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=pd.merge(clean_grade_df,clean_rats_df, on='Date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_merge=pd.merge(clean_grade_df,clean_rats_df, on='ZIPCODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 4: Do certain boroughs have more rat sightings?\n",
    "ratcounting=  clean_rats_df.groupby(['Borough']).size().reset_index(name='count')\n",
    "\n",
    "#ratboroughs = ratcounting['Borough']\n",
    "#ratcounts = ratcounting.groupby('Borough').count()['Complaint Type']\n",
    "\n",
    "\n",
    "#rattransposecounts = ratcounting.pivot(index='Borough', columns=ratboroughs, values=ratcounts).fillna(0)\n",
    "\n",
    "ratcounting.plot(kind='bar', x='Borough', y='count')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Rat Sightings')\n",
    "plt.title('Number of Rat Sightings by Borough, 2010-2017')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count=ratcounting['Borough'].pop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratcounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider per capita data. Find population and divide the rat sightings by the number of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_pops=pd.Series([{'BRONX':1471160},\n",
    "                {'BROOKLYN':2736074},\n",
    "                {'MANHATTAN':1694251},\n",
    "                {'QUEENS':2405464},\n",
    "                {'STATEN ISLAND':495747}],index=)\n",
    "borough_pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_lis=[{'BRONX':1471160},\n",
    "                {'BROOKLYN':2736074},\n",
    "                {'MANHATTAN':1694251},\n",
    "                {'QUEENS':2405464},\n",
    "                {'STATEN ISLAND':495747}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dict_lis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_count=clean_rats_df['Borough'].value_counts()\n",
    "borough_count.pop('Unspecified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_count['BROOKLYN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.Series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
